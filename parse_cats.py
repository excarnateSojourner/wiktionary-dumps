import argparse
import collections
import re
import xml.dom.pulldom

import parse_stubs
import pulldom_helpers

STUBS_VERBOSE_FACTOR = 10 ** 6
SQL_VERBOSE_FACTOR = 400
MASTER_VERBOSE_FACTOR = 10 ** 6
CAT_NAMESPACE = 14
CAT_PREFIX = 'Category:'

CatLink = collections.namedtuple('CatLink', ['cat_id', 'cat_title', 'page_id', 'page_title'])

def main():
	parser = argparse.ArgumentParser(description='Converts a categorylinks.sql file to a more readable, flexible form.')
	parser.add_argument('sql_path', help='Path of the SQL file giving all category associations. This file (after it is unzipped) is called "categorylinks.sql" in the database dumps.')
	parser.add_argument('stubs_path', help='Path of the CSV file containing page ids, namespaces, and titles, generated by parse_stubs.py.')
	parser.add_argument('output_path', help='Path of the CSV file to write the parsed categories to.')
	parser.add_argument('-v', '--verbose', action='store_true')
	args = parser.parse_args()

	if args.verbose:
		print('Loading stubs:')
	page_titles = {}
	cat_ids = {}
	for stub_count, stub in enumerate(parse_stubs.stubs_gen(args.stubs_path)):
		page_titles[stub.id] = stub.title
		if stub.ns == CAT_NAMESPACE:
			cat_ids[stub.title.removeprefix(CAT_PREFIX)] = stub.id
		if args.verbose:
			if stub_count % STUBS_VERBOSE_FACTOR == 0:
				print(stub_count)

	if args.verbose:
		print(f'Loaded {len(page_titles)} page titles and {len(cat_ids)} category ids.')
		print('Processing categories (SQL):')
	with open(args.sql_path, encoding='utf-8', errors='ignore') as sql_file:
		with open(args.output_path, 'w', encoding='utf-8') as out_file:
			for sql_count, line in enumerate(sql_file):
				if line.startswith('INSERT INTO '):
					try:
						line_trimmed = re.match('INSERT INTO `\w*` VALUES \((.*)\);$', line)[1]
					# no match
					except TypeError:
						continue
					rows = [row.split(',', maxsplit=2)[:2] for row in line_trimmed.split('),(')]
					for row in rows:
						cat_title = row[1].replace('_', ' ').replace("\\'", "'").replace('\\"', '"').removeprefix("'").removesuffix("'")
						page_id = int(row[0])
						try:
							print(f'{cat_ids[cat_title]}|{cat_title}|{page_id}|{page_titles[page_id]}', file=out_file)
						except KeyError:
							# a category may not be found if it is in use but has no page
							pass
				if args.verbose and sql_count % SQL_VERBOSE_FACTOR == 0:
					print(sql_count)

def cats_gen(categories_path: str) -> collections.abc.Iterator[CatLink]:
	with open(categories_path, encoding='utf-8') as cats_file:
		for line in cats_file:
			cat_id, cat_title, page_id, page_title = (line[:-1].split('|', maxsplit=3))
			yield CatLink(int(cat_id), cat_title, int(page_id), page_title)

class Cat():
	def __init__(self):
		self.subcats = (set(), set())
		self.pages = (set(), set())

class CategoryMaster():
	def __init__(self, categories_path: str, verbose: bool = False):
		if verbose:
			print('Loading all categories:')
		self.cats = collections.defaultdict(Cat)
		for count, cat_data in enumerate(cats_gen(categories_path)):
			if cat_data.page_title.startswith(CAT_PREFIX):
				self.cats[cat_data.cat_id].subcats[0].add(cat_data.page_id)
				self.cats[cat_data.cat_id].subcats[1].add(cat_data.page_title)
			else:
				self.cats[cat_data.cat_id].pages[0].add(cat_data.page_id)
				self.cats[cat_data.cat_id].pages[1].add(cat_data.page_title)
			if verbose and count % MASTER_VERBOSE_FACTOR == 0:
				print(count)

	def subcats(self, cat_id: int, titles: bool = False) -> set[int] | set[str]:
		return self.cats[cat_id].subcats[1 if titles else 0]

	def pages(self, cat_id: int, titles: bool = False) -> set[int] | set[str]:
		return self.cats[cat_id].pages[1 if titles else 0]

if __name__ == '__main__':
	main()
