import argparse
import collections
import collections.abc
import re

import parse_stubs
import sql_helpers

# Master refers to CategoryMaster
CAT_MASTER_VERBOSE_FACTOR = 10 ** 6
# The MediaWiki category namespace ID
CAT_NAMESPACE_ID = 14

CatLink = collections.namedtuple('CatLink', ['cat_id', 'cat_title', 'page_id', 'page_ns', 'page_title'])

def main() -> None:
	parser = argparse.ArgumentParser(description='Converts a categorylinks.sql file to a more readable, flexible form.')
	parser.add_argument('sql_path', help='Path of the SQL file giving all category associations. This file (after it is unzipped) is called "categorylinks.sql" in the database dumps.')
	parser.add_argument('stubs_path', help='Path of the CSV file containing page ids, namespaces, and titles, generated by parse_stubs.py.')
	parser.add_argument('output_path', help='Path of the CSV file to write the parsed categories to.')
	parser.add_argument('-v', '--verbose', action='store_true')
	args = parser.parse_args()

	if args.verbose:
		print('Reading stubs...')
	stub_master = parse_stubs.StubMaster(args.stubs_path)

	if args.verbose:
		print('Processing categories (SQL):')
	with open(args.output_path, 'w', encoding='utf-8') as out_file:
		for row in sql_helpers.parse_sql(args.sql_path, args.verbose):
			cat_title = row[1].replace('_', ' ')
			page_id = row[0]
			try:
				cat_id = stub_master.id(cat_title, CAT_NAMESPACE_ID)
				print(f'{cat_id}|{cat_title}|{page_id}|{stub_master.ns(page_id)}|{stub_master.title(page_id)}', file=out_file)
			except KeyError:
				# A category may not be found if it is in use but has no page
				pass

def cats_gen(categories_path: str) -> collections.abc.Iterator[CatLink]:
	with open(categories_path, encoding='utf-8') as cats_file:
		for line in cats_file:
			cat_id, cat_title, page_id, page_ns, page_title = (line[:-1].split('|', 4))
			yield CatLink(int(cat_id), cat_title, int(page_id), int(page_ns), page_title)

class Cat():
	def __init__(self):
		# Maps page IDs of subcategories to their titles
		self.subcats: dict[int, str] = {}
		self.pages: set[parse_stubs.Stub] = set()

	def __str__(self) -> str:
		return f'Category ({len(self.subcats)} subcategories and {len(self.pages)} pages)'

class CategoryMaster():
	def __init__(self, categories_path: str, verbose: bool = False):
		if verbose:
			print('Loading all categories:')
		self.cats: dict[int, Cat] = collections.defaultdict(Cat)
		for count, cat_link in enumerate(cats_gen(categories_path)):
			if cat_link.page_ns == CAT_NAMESPACE_ID:
				self.cats[cat_link.cat_id].subcats[cat_link.page_id] = cat_link.page_title
			else:
				self.cats[cat_link.cat_id].pages.add(parse_stubs.Stub(cat_link.page_id, cat_link.page_ns, cat_link.page_title))
			if verbose and count % CAT_MASTER_VERBOSE_FACTOR == 0:
				print(f'{count:,}')

	def subcats(self, cat_id: int, titles: bool = False) -> set[int] | set[str]:
		if titles:
			return set(self.cats[cat_id].subcats.values())
		else:
			return set(self.cats[cat_id].subcats.keys())

	def pages(self, cat_id: int, titles: bool = False) -> set[int] | set[str]:
		if titles:
			return {stub.title for stub in self.cats[cat_id].pages}
		else:
			return {stub.id for stub in self.cats[cat_id].pages}

	def descendant_cats(self, cat_id: int, max_depth: int = -1) -> set[int]:
		des_cats = {cat_id}
		# Purposefully continue if max_depth is negative
		if max_depth != 0:
			for subcat in self.subcats(cat_id):
				des_cats |= self.descendant_cats(subcat, max_depth - 1)
		return des_cats

	def descendant_pages(self, cat_id: int, titles: bool = False, max_depth: int = -1) -> set[int] | set[str]:
		des_pages: set[int] | set[str] = set()
		for cat_id in self.descendant_cats(cat_id, max_depth):
			des_pages |= self.pages(cat_id, titles=titles)
		return des_pages

	def __len__(self) -> int:
		return len(self.cats)

if __name__ == '__main__':
	main()
