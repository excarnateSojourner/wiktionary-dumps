import argparse
import collections
import re
from typing import Iterator
import xml.dom.pulldom

import parse_stubs
import pulldom_helpers

STUBS_VERBOSE_FACTOR = 10 ** 6
SQL_VERBOSE_FACTOR = 400
CATEGORY_NAMESPACE = 14
CATEGORY_PREFIX = 'Category:'

CatData = collections.namedtuple('CatData', ['cat_id', 'cat_title', 'page_id', 'page_title'])

def main():
	parser = argparse.ArgumentParser('Converts a categorylinks.sql file to a more readable, flexible form.')
	parser.add_argument('sql_path', help='Path of the SQL file giving all category associations. This file (after it is unzipped) is called "categorylinks.sql" in the database dumps.')
	parser.add_argument('stubs_path', help='Path of the CSV file containing page ids, namespaces, and titles, generated by parse_stubs.py.')
	parser.add_argument('output_path', help='Path of the CSV file to write the parsed categories to.')
	parser.add_argument('-v', '--verbose', action='store_true')
	args = parser.parse_args()

	if args.verbose:
		print('Loading stubs:')
	page_titles = {}
	cat_ids = {}
	for stub_count, stub in enumerate(parse_stubs.stubs_gen(args.stubs_path)):
		page_titles[stub.id] = stub.title
		if stub.ns == CATEGORY_NAMESPACE:
			cat_ids[stub.title.removeprefix(CATEGORY_PREFIX)] = stub.id
		if args.verbose:
			if stub_count % STUBS_VERBOSE_FACTOR == 0:
				print(stub_count)

	if args.verbose:
		print(f'Loaded {len(page_titles)} page titles and {len(cat_ids)} category ids.')
		print('Processing categories (SQL):')
	with open(args.sql_path, encoding='utf-8', errors='ignore') as sql_file:
		with open(args.output_path, 'w', encoding='utf-8') as out_file:
			for sql_count, line in enumerate(sql_file):
				if line.startswith('INSERT INTO '):
					try:
						line_trimmed = re.match('INSERT INTO `\w*` VALUES \((.*)\);$', line)[1]
					# no match
					except TypeError:
						continue
					rows = [row.split(',', maxsplit=2)[:2] for row in line_trimmed.split('),(')]
					for row in rows:
						cat_title = row[1].replace('_', ' ').replace("\\'", "'").replace('\\"', '"').removeprefix("'").removesuffix("'")
						page_id = int(row[0])
						try:
							print(f'{cat_ids[cat_title]}|{cat_title}|{page_id}|{page_titles[page_id]}', file=out_file)
						except KeyError:
							# a category may not be found if it is in use but has no page
							pass
				if args.verbose and sql_count % SQL_VERBOSE_FACTOR == 0:
					print(sql_count)

def cats_gen(categories_path: str) -> Iterator[CatData]:
	with open(categories_path, encoding='utf-8') as cats_file:
		for line in cats_file:
			fields = (line[:-1].split('|', maxsplit=3))
			yield CatData(cat_id=int(fields[0]), cat_title=fields[1], page_id=int(fields[2]), page_title=fields[3])

if __name__ == '__main__':
	main()
